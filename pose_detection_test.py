import cv2
import mediapipe as mp
import numpy as np
import os
from PIL import Image, ImageDraw, ImageFont
from typing import Optional, Tuple, List, Any

# Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ MediaPipe
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
mp_hands = mp.solutions.hands

class PoseDetector:
    """Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù¾ÙˆØ² Ø¨Ø§ Ø¯Ú©Ù…Ù‡ Ù„Ù…Ø³ÛŒ Ù…Ø¬Ø§Ø²ÛŒ"""
    
    def __init__(self, 
                 static_image_mode: bool = False,
                 model_complexity: int = 1,
                 min_detection_confidence: float = 0.7,
                 min_tracking_confidence: float = 0.5):
        
        self.pose_detector = mp_pose.Pose(
            static_image_mode=static_image_mode,
            model_complexity=model_complexity,
            min_detection_confidence=min_detection_confidence,
            min_tracking_confidence=min_tracking_confidence
        )
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ ØªØ´Ø®ÛŒØµ Ø¯Ø³Øª Ø¨Ø±Ø§ÛŒ Ø§Ù†Ú¯Ø´Øª
        self.hand_detector = mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        
        self.cap = None
        self.button_cooldown = 0  # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¹Ú©Ø³â€ŒÙ‡Ø§ÛŒ Ù¾Ø´Øª Ø³Ø± Ù‡Ù…

    def get_persian_font(self) -> Optional[str]:
        """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ø³Ø§Ø¯Ù‡"""
        persian_fonts = [
            'Vazir.ttf', 'Vazir-Regular.ttf', 'Vazir-FD.ttf',
            'B Nazanin.ttf', 'B Yekan.ttf',
            'IRANSans.ttf', 'IRANSansWeb.ttf',
            'Shabnam.ttf', 'Shabnam-FD.ttf',
            'Tahoma.ttf', 'Arial.ttf'
        ]
        
        font_paths = [
            'C:/Windows/Fonts/',
            os.path.expanduser('~/AppData/Local/Microsoft/Windows/Fonts/'),
            './fonts/'
        ]
        
        current_user = os.getenv('USERNAME') or os.getenv('USER')
        if current_user:
            user_font_path = f'C:/Users/{current_user}/AppData/Local/Microsoft/Windows/Fonts/'
            font_paths.append(user_font_path)
        
        for font_path in font_paths:
            if os.path.exists(font_path):
                try:
                    available_fonts = os.listdir(font_path)
                    for font in persian_fonts:
                        if font in available_fonts:
                            return os.path.join(font_path, font)
                except (PermissionError, FileNotFoundError):
                    continue
        
        return None

    def put_persian_text(self, img: np.ndarray, text: str, position: Tuple[int, int], 
                        font_scale: float = 1.0, color: Tuple[int, int, int] = (0, 0, 0)) -> np.ndarray:
        """Ù†Ù…Ø§ÛŒØ´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø±ÙˆÛŒ ØªØµÙˆÛŒØ±"""
        try:
            import arabic_reshaper
            from bidi.algorithm import get_display
            
            reshaped_text = arabic_reshaper.reshape(text)
            bidi_text = get_display(reshaped_text)
            
            img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(img_pil)
            
            font_path = self.get_persian_font()
            font_size = max(20, int(28 * font_scale))
            
            if font_path and os.path.exists(font_path):
                font = ImageFont.truetype(font_path, font_size)
            else:
                font = None
            
            if font:
                draw.text(position, bidi_text, font=font, fill=color)
            else:
                draw.text(position, bidi_text, fill=color)
            
            return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
            
        except ImportError:
            cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX, 
                       font_scale, color, 2)
            return img
        except Exception:
            cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX, 
                       font_scale, color, 2)
            return img

    def initialize_camera(self, camera_index: int = 0) -> bool:
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯ÙˆØ±Ø¨ÛŒÙ†"""
        try:
            self.cap = cv2.VideoCapture(camera_index)
            
            if not self.cap.isOpened():
                for i in range(1, 3):
                    self.cap = cv2.VideoCapture(i)
                    if self.cap.isOpened():
                        break
                else:
                    return False
            
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            print("âœ… Camera initialized - Press 'q' to quit")
            print("ğŸ–ï¸ Touch the virtual button with your finger to take photo!")
            return True
            
        except Exception as e:
            print(f"âŒ Camera error: {e}")
            return False

    def process_frame(self, frame: np.ndarray) -> Tuple[Any, Any]:
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ±ÛŒÙ… Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù¾ÙˆØ² Ùˆ Ø¯Ø³Øª"""
        try:
            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # ØªØ´Ø®ÛŒØµ Ù¾ÙˆØ²
            pose_results = self.pose_detector.process(image_rgb)
            
            # ØªØ´Ø®ÛŒØµ Ø¯Ø³Øª
            hand_results = self.hand_detector.process(image_rgb)
            
            return pose_results, hand_results
        except Exception:
            return None, None

    def draw_landmarks(self, frame: np.ndarray, pose_results: Any, hand_results: Any) -> np.ndarray:
        """Ø±Ø³Ù… Ø§Ø³Ú©Ù„Øª Ø¨Ø¯Ù† Ùˆ Ù†Ù‚Ø§Ø· Ø¯Ø³Øª"""
        # Ø±Ø³Ù… Ø§Ø³Ú©Ù„Øª Ø¨Ø¯Ù†
        if pose_results and pose_results.pose_landmarks:
            mp_drawing.draw_landmarks(
                frame,
                pose_results.pose_landmarks,
                mp_pose.POSE_CONNECTIONS,
                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),
                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)
            )
        
        # Ø±Ø³Ù… Ù†Ù‚Ø§Ø· Ø¯Ø³Øª (Ø§Ø®ØªÛŒØ§Ø±ÛŒ - Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯)
        if hand_results and hand_results.multi_hand_landmarks:
            for hand_landmarks in hand_results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(
                    frame,
                    hand_landmarks,
                    mp_hands.HAND_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=2, circle_radius=3),
                    mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)
                )
        
        return frame

    def is_finger_touching_button(self, hand_results: Any, frame_shape: Tuple[int, int], 
                                button_pos: Tuple[int, int, int, int]) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ø§Ù†Ú¯Ø´Øª Ú©Ø§Ø±Ø¨Ø± Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡ Ø§Ø³Øª"""
        if not hand_results or not hand_results.multi_hand_landmarks:
            return False
        
        h, w = frame_shape[:2]
        button_x1, button_y1, button_x2, button_y2 = button_pos
        
        for hand_landmarks in hand_results.multi_hand_landmarks:
            # Ú¯Ø±ÙØªÙ† Ù…ÙˆÙ‚Ø¹ÛŒØª Ù†ÙˆÚ© Ø§Ù†Ú¯Ø´Øª Ø§Ø´Ø§Ø±Ù‡ (landmark 8)
            fingertip = hand_landmarks.landmark[8]
            
            # ØªØ¨Ø¯ÛŒÙ„ Ù…Ø®ØªØµØ§Øª Ù†Ø³Ø¨ÛŒ Ø¨Ù‡ Ù¾ÛŒÚ©Ø³Ù„
            fingertip_x = int(fingertip.x * w)
            fingertip_y = int(fingertip.y * h)
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø±Ø®ÙˆØ±Ø¯ Ø¨Ø§ Ø¯Ú©Ù…Ù‡
            if (button_x1 <= fingertip_x <= button_x2 and 
                button_y1 <= fingertip_y <= button_y2):
                return True
        
        return False

    def draw_virtual_button(self, frame: np.ndarray, is_touching: bool) -> Tuple[np.ndarray, Tuple[int, int, int, int]]:
        """Ø±Ø³Ù… Ø¯Ú©Ù…Ù‡ Ù…Ø¬Ø§Ø²ÛŒ Ùˆ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¢Ù†"""
        h, w = frame.shape[:2]
        
        # Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¯Ú©Ù…Ù‡ - Ú¯ÙˆØ´Ù‡ Ø¨Ø§Ù„Ø§ Ø±Ø§Ø³Øª
        button_width, button_height = 120, 60
        button_x1, button_y1 = w - button_width - 20, 20
        button_x2, button_y2 = button_x1 + button_width, button_y1 + button_height
        
        # Ø±Ù†Ú¯ Ø¯Ú©Ù…Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø§Ù„Øª
        button_color = (0, 200, 0) if is_touching else (200, 200, 200)  # Ø³Ø¨Ø² Ù‡Ù†Ú¯Ø§Ù… Ù„Ù…Ø³
        text_color = (255, 255, 255) if is_touching else (0, 0, 0)
        
        # Ø±Ø³Ù… Ø¯Ú©Ù…Ù‡
        cv2.rectangle(frame, (button_x1, button_y1), (button_x2, button_y2), button_color, -1)
        cv2.rectangle(frame, (button_x1, button_y1), (button_x2, button_y2), (0, 0, 0), 2)
        
        # Ù…ØªÙ† Ø¯Ú©Ù…Ù‡
        button_text = "Ø¹Ú©Ø³ ğŸ“¸" if is_touching else "Ø¹Ú©Ø³"
        text_size = cv2.getTextSize(button_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
        text_x = button_x1 + (button_width - text_size[0]) // 2
        text_y = button_y1 + (button_height + text_size[1]) // 2
        
        cv2.putText(frame, button_text, (text_x, text_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 2)
        
        return frame, (button_x1, button_y1, button_x2, button_y2)

    def take_screenshot(self, frame: np.ndarray) -> str:
        """Ø°Ø®ÛŒØ±Ù‡ Ø¹Ú©Ø³ Ø§Ø² ÙØ±ÛŒÙ… ÙØ¹Ù„ÛŒ"""
        try:
            timestamp = cv2.getTickCount()
            filename = f"touch_capture_{timestamp}.jpg"
            
            cv2.imwrite(filename, frame)
            print(f"âœ… Ø¹Ú©Ø³ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename}")
            return filename
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¹Ú©Ø³: {e}")
            return ""

    def display_minimal_ui(self, frame: np.ndarray, pose_results: Any, 
                         hand_results: Any, button_pos: Tuple[int, int, int, int]) -> np.ndarray:
        """Ù†Ù…Ø§ÛŒØ´ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ù…ÛŒÙ†ÛŒÙ…Ø§Ù„ Ø¨Ø§ Ø¯Ú©Ù…Ù‡ Ù„Ù…Ø³ÛŒ"""
        h, w = frame.shape[:2]
        
        # ÙˆØ¶Ø¹ÛŒØª ØªØ´Ø®ÛŒØµ - Ú¯ÙˆØ´Ù‡ Ø¨Ø§Ù„Ø§ Ú†Ù¾
        status_text = "ÙˆØ¶Ø¹ÛŒØª: ÙØ¹Ø§Ù„" if pose_results and pose_results.pose_landmarks else "ÙˆØ¶Ø¹ÛŒØª: ØºÛŒØ±ÙØ¹Ø§Ù„"
        status_color = (0, 100, 0) if pose_results and pose_results.pose_landmarks else (0, 0, 100)
        frame = self.put_persian_text(frame, status_text, (20, 20), 0.8, status_color)
        
        # Ù†Ù…Ø§ÛŒØ´ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù„Ù…Ø³ÛŒ
        guide_text = "Ø§Ù†Ú¯Ø´Øª Ø®ÙˆØ¯ Ø±Ø§ Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡ Ø¨Ø¨Ø±ÛŒØ¯"
        frame = self.put_persian_text(frame, guide_text, (20, h - 30), 0.6, (100, 100, 100))
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù„Ù…Ø³ Ø¯Ú©Ù…Ù‡
        is_touching = self.is_finger_touching_button(hand_results, frame.shape, button_pos)
        
        # Ú©Ø§Ù‡Ø´ Ú©ÙˆÙ„â€ŒØ¯Ø§ÙˆÙ†
        if self.button_cooldown > 0:
            self.button_cooldown -= 1
        
        # Ø§Ú¯Ø± Ø§Ù†Ú¯Ø´Øª Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡ Ø§Ø³Øª Ùˆ Ú©ÙˆÙ„â€ŒØ¯Ø§ÙˆÙ† ØªÙ…Ø§Ù… Ø´Ø¯Ù‡
        if is_touching and self.button_cooldown == 0:
            self.take_screenshot(frame)
            self.button_cooldown = 30  # 30 ÙØ±ÛŒÙ… Ú©ÙˆÙ„â€ŒØ¯Ø§ÙˆÙ† (Ø­Ø¯ÙˆØ¯ 1 Ø«Ø§Ù†ÛŒÙ‡)
        
        return frame, is_touching

    def run(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡"""
        if not self.initialize_camera():
            return
        
        try:
            while True:
                ret, frame = self.cap.read()
                if not ret:
                    break
                
                # Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ±ÛŒÙ…
                frame = cv2.flip(frame, 1)
                pose_results, hand_results = self.process_frame(frame)
                
                # Ù…ÙˆÙ‚Ø¹ÛŒØª Ø«Ø§Ø¨Øª Ø¯Ú©Ù…Ù‡
                h, w = frame.shape[:2]
                button_pos = (w - 140, 20, w - 20, 80)  # x1, y1, x2, y2
                
                # Ø±Ø³Ù… Ø§Ø³Ú©Ù„Øª Ø¨Ø¯Ù† Ùˆ Ø¯Ø³Øª
                frame = self.draw_landmarks(frame, pose_results, hand_results)
                
                # Ø±Ø³Ù… Ø¯Ú©Ù…Ù‡ Ù…Ø¬Ø§Ø²ÛŒ
                is_touching = self.is_finger_touching_button(hand_results, frame.shape, button_pos)
                frame = self.draw_virtual_button(frame, is_touching)[0]
                
                # Ù†Ù…Ø§ÛŒØ´ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ
                frame, _ = self.display_minimal_ui(frame, pose_results, hand_results, button_pos)
                
                # Ù†Ù…Ø§ÛŒØ´ ÙØ±ÛŒÙ…
                cv2.imshow('Pose Detection - Virtual Touch', frame)
                
                # Ø®Ø±ÙˆØ¬ Ø¨Ø§ Ú©Ù„ÛŒØ¯ q
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
                    
        except KeyboardInterrupt:
            print("\nâ¹ï¸ Program stopped by user")
        except Exception as e:
            print(f"âŒ Unexpected error: {e}")
        finally:
            self.cleanup()

    def cleanup(self):
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹"""
        try:
            if self.cap:
                self.cap.release()
            cv2.destroyAllWindows()
            self.pose_detector.close()
            self.hand_detector.close()
            print("âœ… Resources released")
        except:
            pass

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    print("ğŸš€ Starting Pose Detection with Virtual Touch...")
    
    try:
        detector = PoseDetector()
        detector.run()
    except Exception as e:
        print(f"âŒ Program error: {e}")
    finally:
        print("ğŸ‘‹ Program ended")

if __name__ == "__main__":
    main()