import cv2
import mediapipe as mp
import numpy as np
import os
import time
# ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø±Ù†Ø¯Ø± ÙØ§Ø±Ø³ÛŒ
import arabic_reshaper 
from bidi.algorithm import get_display
from PIL import Image, ImageDraw, ImageFont
from typing import Optional, Tuple, List, Any
import threading

# Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ MediaPipe
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
mp_hands = mp.solutions.hands
mp_face_detection = mp.solutions.face_detection
# ------------------------------------------------------------------------------------------------------

class SuperPoseDetector:
    """Ø³ÙˆÙ¾Ø± Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† ØªØ´Ø®ÛŒØµ Ù¾ÙˆØ² Ø¨Ø§ ØªÙ…Ø§Ù… Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
    
    def __init__(self):
        # ------------------------
        # Û±. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ MediaPipe
        # ------------------------
        self.pose_detector = mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5
        )
        self.hand_detector = mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.face_detector = mp_face_detection.FaceDetection(
            model_selection=0,
            min_detection_confidence=0.5
        )
        
        # ------------------------
        # Û². ØªØ¹Ø±ÛŒÙ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª
        # ------------------------
        self.cap = None
        self.video_writer = None
        
        # ÙˆØ¶Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ú©Ù†ØªØ±Ù„ÛŒ
        self.button_cooldown = 0
        self.is_recording = False
        self.timer_active = False
        self.current_filter = "normal" 
        self.flash_effect = 0
        
        # Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§ Ùˆ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡â€ŒÙ‡Ø§
        self.recording_start_time = 0
        self.timer_countdown = 0 
        self.last_gesture_time = 0
        self.photo_count = 0
        self.video_count = 0 

        # ------------------------
        # Û³. Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ (Threading) Ùˆ ÙÙˆÙ†Øª
        # ------------------------
        # Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±Ø¹Øª
        self.frame_to_process = None # ÙØ±ÛŒÙ… Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙˆØ³Ø· Ø±Ø´ØªÙ‡ Ø¯ÙˆÙ…
        self.process_results = {'pose': None, 'hand': None, 'face': None} # Ù†ØªØ§ÛŒØ¬ Ø¢Ø®Ø±ÛŒÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´
        
        # Û±. Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙÙˆÙ†Øª: ÙÙˆÙ†Øª Ø±Ø§ ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø± Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        self.persian_font_path = self.get_persian_font() 
        
        # Û². Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø´ØªÙ‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ
        self.processing_thread = threading.Thread(target=self._run_processing_loop, daemon=True)
        self.processing_thread.start()
        
        # Û³. Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
        self.create_folders()

    def create_folders(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²"""
        folders = ['photos', 'videos', 'gestures']
        for folder in folders:
            if not os.path.exists(folder):
                os.makedirs(folder)
                
    # ------------------------------------------------------------------------------------------------------
    # ØªÙˆØ§Ø¨Ø¹ Ø±Ù†Ø¯Ø± ÙØ§Ø±Ø³ÛŒ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù„ÙˆØ¯ ÙÙˆÙ†Øª ÛŒÚ© Ø¨Ø§Ø±)
    # ------------------------------------------------------------------------------------------------------

    def get_persian_font(self) -> Optional[str]:
        """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ B NazaninØŒ IRANSans ÛŒØ§ Tahoma"""
        # Ù„ÛŒØ³Øª ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ø±Ø§ÛŒØ¬
        persian_fonts = ['BNazanin.ttf', 'B Nazanin.ttf', 'IRANSans.ttf', 'Tahoma.ttf', 'Vazir.ttf', 'arial.ttf']
        
        # Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ÙˆÛŒÙ†Ø¯ÙˆØ² Ùˆ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±
        font_paths = [
            'C:/Windows/Fonts/',         # Ø¢Ø¯Ø±Ø³ Ù…Ø³ØªÙ‚ÛŒÙ… ÙˆÛŒÙ†Ø¯ÙˆØ²
            'C:\\Windows\\Fonts\\',      # Ø¢Ø¯Ø±Ø³ ÙˆÛŒÙ†Ø¯ÙˆØ² Ø¨Ø§ Ø¨Ú©â€ŒØ§Ø³Ù„Ø´
            '/usr/share/fonts/truetype/', # Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø±Ø§ÛŒØ¬ Ù„ÛŒÙ†ÙˆÚ©Ø³
            '/System/Library/Fonts/',     # Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø±Ø§ÛŒØ¬ Ù…Ú©
            os.path.expanduser('~/.fonts/'), # Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ù„ÛŒÙ†ÙˆÚ©Ø³/Ù…Ú©
            os.path.expanduser('~/AppData/Local/Microsoft/Windows/Fonts/'), # Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ÙˆÛŒÙ†Ø¯ÙˆØ² Ú©Ø§Ø±Ø¨Ø±ÛŒ
            '.'                          # Ù¾ÙˆØ´Ù‡ Ø¬Ø§Ø±ÛŒ
        ]
        
        for font_path in font_paths:
            # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ù…Ø³ÛŒØ±
            if os.path.exists(font_path):
                for font in persian_fonts:
                    full_path = os.path.join(font_path, font)
                    if os.path.exists(full_path):
                        return full_path
                        
        return None # Ø§Ú¯Ø± Ù‡ÛŒÚ† ÙÙˆÙ†ØªÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯
    
    def put_persian_text(self, img: np.ndarray, text: str, position: Tuple[int, int], 
                          font_scale: float = 1.0, color: Tuple[int, int, int] = (0, 0, 0)) -> np.ndarray:
        """Ù†Ù…Ø§ÛŒØ´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Pillow Ùˆ Bidi Ø¨Ø±Ø§ÛŒ ØªØµØ­ÛŒØ­ Ø±Ù†Ø¯Ø±"""
        try:
            # Û±. ØªØµØ­ÛŒØ­ ÙØ§Ø±Ø³ÛŒ Ùˆ Ø¬Ù‡Øªâ€ŒØ¯Ù‡ÛŒ (CTL)
            reshaped_text = arabic_reshaper.reshape(text)
            bidi_text = get_display(reshaped_text)
            
            # Û². ØªØ¨Ø¯ÛŒÙ„ OpenCV Ø¨Ù‡ Pillow
            img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(img_pil)
            
            # Û³. Ù…Ø¯ÛŒØ±ÛŒØª ÙÙˆÙ†Øª Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡
            base_size = 30 
            font_size = max(30, int(base_size * font_scale)) # Ø­Ø¯Ø§Ù‚Ù„ Ø§Ù†Ø¯Ø§Ø²Ù‡ 30 Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø³ÛŒØ± ÙÙˆÙ†Øª Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø¯Ø± __init__
            if self.persian_font_path:
                font = ImageFont.truetype(self.persian_font_path, font_size)
            else:
                # Fallback Ø¨Ù‡ ÙÙˆÙ†Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø§ Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØ¹ÛŒÛŒÙ† Ø´Ø¯Ù‡
                font = ImageFont.load_default(size=font_size)
                
            # Û´. ØªØ±Ø³ÛŒÙ… Ù…ØªÙ†
            draw.text(position, bidi_text, font=font, fill=color)
            
            # Ûµ. Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ ÙØ±Ù…Øª OpenCV
            return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
            
        except Exception as e:
            # Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ØŒ Ø¨Ù‡ cv2.putText Ø¨Ø±Ú¯Ø±Ø¯
            # print(f"Error in put_persian_text: {e}")
            cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), 2)
            return img

    # ------------------------------------------------------------------------------------------------------
    # ØªÙˆØ§Ø¨Ø¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ Ùˆ Ú©Ù…Ú©ÛŒ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Threading)
    # ------------------------------------------------------------------------------------------------------
    
    def _run_processing_loop(self):
        """Ø­Ù„Ù‚Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ Ù†Ø§Ù‡Ù…Ø²Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ MP"""
        while True:
            if self.frame_to_process is not None:
                # Ú©Ù¾ÛŒ Ú©Ø±Ø¯Ù† ÙØ±ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Race Condition
                frame = self.frame_to_process.copy() 
                self.frame_to_process = None # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ±ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ù¾Ø°ÛŒØ±Ø´ ÙØ±ÛŒÙ… Ø¨Ø¹Ø¯ÛŒ
                
                try:
                    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    pose_results = self.pose_detector.process(image_rgb)
                    hand_results = self.hand_detector.process(image_rgb)
                    face_results = self.face_detector.process(image_rgb)
                    
                    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± Ù…ØªØºÛŒØ± Ù…Ø´ØªØ±Ú©
                    self.process_results = {
                        'pose': pose_results, 
                        'hand': hand_results, 
                        'face': face_results
                    }
                except Exception as e:
                    # print(f"Error in processing thread: {e}")
                    self.process_results = {'pose': None, 'hand': None, 'face': None}
            # Ú©Ø§Ù‡Ø´ Ø¨Ø§Ø± CPU Ø¨Ø§ Sleep (Ø¨Ø±Ø§ÛŒ Threading Ù…Ù‡Ù… Ø§Ø³Øª)
            time.sleep(0.005) 

    def process_frame(self, frame: np.ndarray) -> Tuple[Any, Any, Any]:
        """Ø§Ø±Ø³Ø§Ù„ ÙØ±ÛŒÙ… Ø¨Ù‡ Ø±Ø´ØªÙ‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† Ù†ØªØ§ÛŒØ¬"""
        # ÙÙ‚Ø· ÙØ±ÛŒÙ… Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± Ø±Ø´ØªÙ‡ Ø¯ÛŒÚ¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        self.frame_to_process = frame.copy()
        
        # Ø¨Ø§Ø²Ú¯Ø´Øª Ø¢Ø®Ø±ÛŒÙ† Ù†ØªØ§ÛŒØ¬ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡
        return self.process_results.get('pose'), self.process_results.get('hand'), self.process_results.get('face')
    
    def apply_filter(self, frame: np.ndarray, filter_name: str) -> np.ndarray:
        """Ø§Ø¹Ù…Ø§Ù„ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø±Ù†Ú¯ÛŒ Ù…Ø®ØªÙ„Ù"""
        if filter_name == "normal":
            return frame
        elif filter_name == "sepia":
            kernel = np.array([[0.272, 0.534, 0.131],
                               [0.349, 0.686, 0.168],
                               [0.393, 0.769, 0.189]])
            return cv2.transform(frame, kernel)
        elif filter_name == "grayscale":
            return cv2.cvtColor(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), cv2.COLOR_GRAY2BGR)
        elif filter_name == "warm":
            frame = frame.astype(np.float32)
            frame[:, :, 0] = frame[:, :, 0] * 0.7   # Ú©Ø§Ù‡Ø´ Ø¢Ø¨ÛŒ
            frame[:, :, 2] = frame[:, :, 2] * 1.3   # Ø§ÙØ²Ø§ÛŒØ´ Ù‚Ø±Ù…Ø²
            return np.clip(frame, 0, 255).astype(np.uint8)
        elif filter_name == "cool":
            frame = frame.astype(np.float32)
            frame[:, :, 0] = frame[:, :, 0] * 1.3   # Ø§ÙØ²Ø§ÛŒØ´ Ø¢Ø¨ÛŒ
            frame[:, :, 2] = frame[:, :, 2] * 0.7   # Ú©Ø§Ù‡Ø´ Ù‚Ø±Ù…Ø²
            return np.clip(frame, 0, 255).astype(np.uint8)
        return frame
    
    def detect_gestures(self, hand_results: Any) -> str:
        """ØªØ´Ø®ÛŒØµ Ú˜Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø¯Ø³Øª (âœŒï¸ ØµÙ„Ø­ Ùˆ ğŸ‘ Ø´Ø³Øª Ø¨Ø§Ù„Ø§)"""
        if not hand_results or not hand_results.multi_hand_landmarks:
            return ""
            
        current_time = time.time()
        # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªØ´Ø®ÛŒØµ Ù¾Ø´Øª Ø³Ø± Ù‡Ù… (Ú©ÙˆÙ„â€ŒØ¯Ø§ÙˆÙ† Ú˜Ø³Øª)
        if current_time - self.last_gesture_time < 2: 
            return ""
            
        for hand_landmarks in hand_results.multi_hand_landmarks:
            landmarks = hand_landmarks.landmark
            
            # âœŒï¸ Ø¹Ù„Ø§Ù…Øª V (ØµÙ„Ø­)
            if (landmarks[8].y < landmarks[6].y and   # Ø§Ù†Ú¯Ø´Øª Ø§Ø´Ø§Ø±Ù‡ Ø¨Ø§Ù„Ø§
                landmarks[12].y < landmarks[10].y and   # Ø§Ù†Ú¯Ø´Øª ÙˆØ³Ø· Ø¨Ø§Ù„Ø§
                landmarks[16].y > landmarks[14].y and   # Ø§Ù†Ú¯Ø´Øª Ø­Ù„Ù‚Ù‡ Ù¾Ø§ÛŒÛŒÙ†
                landmarks[20].y > landmarks[18].y):     # Ø§Ù†Ú¯Ø´Øª Ú©ÙˆÚ†Ú© Ù¾Ø§ÛŒÛŒÙ†
                self.last_gesture_time = current_time
                return "peace"
            
            # ğŸ‘ Ø´Ø³Øª Ø¨Ø§Ù„Ø§
            if (landmarks[4].y < landmarks[3].y and   # Ø´Ø³Øª Ø¨Ø§Ù„Ø§
                landmarks[8].y > landmarks[6].y and   # Ø³Ø§ÛŒØ± Ø§Ù†Ú¯Ø´ØªØ§Ù† Ù¾Ø§ÛŒÛŒÙ†
                landmarks[12].y > landmarks[10].y and
                landmarks[16].y > landmarks[14].y and
                landmarks[20].y > landmarks[18].y):
                self.last_gesture_time = current_time
                return "thumbs_up"
                
        return ""
        
    def detect_smile(self, face_results: Any) -> bool:
        """ØªØ´Ø®ÛŒØµ Ù„Ø¨Ø®Ù†Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ ØµÙˆØ±Øª"""
        # MediaPipe Face Detection ÙÙ‚Ø· Ú©Ø§Ø¯Ø± ØµÙˆØ±Øª Ø±Ø§ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ØŒ Ù†Ù‡ Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚ Ø¯Ù‡Ø§Ù†.
        # Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù‚Ø§Ø¨Ù„ÛŒØªØŒ Ø§Ú¯Ø± ØµÙˆØ±Øª ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯ØŒ True Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ….
        return bool(face_results and face_results.detections) 
        
    def take_photo(self, frame: np.ndarray):
        """Ú¯Ø±ÙØªÙ† Ø¹Ú©Ø³ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¢Ù†"""
        self.photo_count += 1
        filename = f"photos/photo_{time.strftime('%Y%m%d_%H%M%S')}_{self.photo_count}.png"
        cv2.imwrite(filename, frame)
        print(f"ğŸ“¸ Ø¹Ú©Ø³ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename}")
        self.flash_effect = 5 # ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† ÙÙ„Ø´ Ø¨Ø±Ø§ÛŒ 5 ÙØ±ÛŒÙ…
        
    def toggle_recording(self):
        """Ø´Ø±ÙˆØ¹/ØªÙˆÙ‚Ù Ø¶Ø¨Ø· ÙˆÛŒØ¯ÛŒÙˆ"""
        if not self.is_recording:
            # Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø·
            self.video_count += 1
            filename = f"videos/video_{time.strftime('%Y%m%d_%H%M%S')}_{self.video_count}.avi"
            
            # Ú¯Ø±ÙØªÙ† Ø§Ø¨Ø¹Ø§Ø¯ Ùˆ FPS Ø§Ø² Ú©Ù¾Ú†Ø± Ø¯ÙˆØ±Ø¨ÛŒÙ†
            w = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = self.cap.get(cv2.CAP_PROP_FPS) if self.cap and self.cap.get(cv2.CAP_PROP_FPS) > 0 else 30.0
            
            fourcc = cv2.VideoWriter_fourcc(*'MJPG')
            self.video_writer = cv2.VideoWriter(filename, fourcc, fps, (w, h))
            self.recording_start_time = time.time()
            self.is_recording = True
            print(f"ğŸ”´ Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø· ÙˆÛŒØ¯ÛŒÙˆ: {filename}")
        else:
            # ØªÙˆÙ‚Ù Ø¶Ø¨Ø·
            if self.video_writer:
                self.video_writer.release()
            self.video_writer = None
            self.is_recording = False
            print("â¹ï¸ Ù¾Ø§ÛŒØ§Ù† Ø¶Ø¨Ø· ÙˆÛŒØ¯ÛŒÙˆ")
            
    def start_timer(self):
        """Ø´Ø±ÙˆØ¹ ØªØ§ÛŒÙ…Ø± Û³ Ø«Ø§Ù†ÛŒÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¹Ú©Ø³"""
        if not self.timer_active:
            self.timer_active = True
            # ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ø§ Ø­Ø¯ÙˆØ¯ Û³Û° ÙØ±ÛŒÙ… Ø¨Ø± Ø«Ø§Ù†ÛŒÙ‡ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯
            self.timer_countdown = 3 * 30 
            print("â³ ØªØ§ÛŒÙ…Ø± Ø´Ø±ÙˆØ¹ Ø´Ø¯ (Û³ Ø«Ø§Ù†ÛŒÙ‡)")
            
    # --- ØªÙˆØ§Ø¨Ø¹ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ ---
    
    def is_finger_touching_button(self, hand_results: Any, frame_shape: Tuple[int, int], 
                                  button_pos: Tuple[int, int, int, int]) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ù„Ù…Ø³ Ø¯Ú©Ù…Ù‡ Ø¨Ø§ Ø§Ù†Ú¯Ø´Øª"""
        if not hand_results or not hand_results.multi_hand_landmarks:
            return False
        
        h, w = frame_shape[:2]
        button_x1, button_y1, button_x2, button_y2 = button_pos
        
        for hand_landmarks in hand_results.multi_hand_landmarks:
            # Ù„Ù†Ø¯Ù…Ø§Ø±Ú© Ø´Ù…Ø§Ø±Ù‡ Û¸ Ù†ÙˆÚ© Ø§Ù†Ú¯Ø´Øª Ø§Ø´Ø§Ø±Ù‡ (INDEX_FINGER_TIP) Ø§Ø³Øª.
            fingertip = hand_landmarks.landmark[8]  
            
            # ØªØ¨Ø¯ÛŒÙ„ Ù…Ø®ØªØµØ§Øª Ù†Ø±Ù…Ø§Ù„Ø§ÛŒØ² Ø´Ø¯Ù‡ Ø¨Ù‡ Ù…Ø®ØªØµØ§Øª Ù¾ÛŒÚ©Ø³Ù„ÛŒ
            fingertip_x = int(fingertip.x * w)
            fingertip_y = int(fingertip.y * h)
            
            # Ø¢ÛŒØ§ Ù†ÙˆÚ© Ø§Ù†Ú¯Ø´Øª Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¯Ú©Ù…Ù‡ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯ØŸ
            if (button_x1 <= fingertip_x <= button_x2 and 
                button_y1 <= fingertip_y <= button_y2):
                return True
        
        return False

    def draw_virtual_buttons(self, frame: np.ndarray, hand_results: Any) -> Tuple[np.ndarray, dict]:
        """Ø±Ø³Ù… ØªÙ…Ø§Ù… Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø§Ø²ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ù„Ù…Ø³"""
        h, w = frame.shape[:2]
        buttons = {}
        
        # ğŸ¨ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ ÙÛŒÙ„ØªØ± (Ø³ØªÙˆÙ† Ø³Ù…Øª Ú†Ù¾) - ÙØ§Ø±Ø³ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
        filters = {"Ø¹Ø§Ø¯ÛŒ": "normal", "Ø³Ù¾ÛŒØ§": "sepia", "Ø³ÛŒØ§Ù‡â€ŒØ³ÙÛŒØ¯": "grayscale", "Ú¯Ø±Ù…": "warm", "Ø³Ø±Ø¯": "cool"}
        button_height = 50
        
        for i, (persian_name, filter_key) in enumerate(filters.items()):
            y1 = 20 + i * (button_height + 10)
            y2 = y1 + button_height
            x1, x2 = 20, 120
            
            is_active = self.current_filter == filter_key
            color = (0, 200, 0) if is_active else (100, 100, 100)
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ù„Ù…Ø³ Ùˆ Ø§Ø¹Ù…Ø§Ù„ ÙÛŒÙ„ØªØ±
            is_touching = self.is_finger_touching_button(hand_results, frame.shape, (x1, y1, x2, y2))
            if is_touching and self.button_cooldown == 0:
                self.current_filter = filter_key
                self.button_cooldown = 20
            
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, -1)
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 2)
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ ØµØ­ÛŒØ­ Ø§Ø² persian_name Ø¨Ø±Ø§ÛŒ Ø±Ù†Ø¯Ø± ÙØ§Ø±Ø³ÛŒ
            text = persian_name 
            frame = self.put_persian_text(frame, text, (x1 + 10, y1 + 10), 0.7, (255, 255, 255))
            
            buttons[f"filter_{filter_key}"] = (x1, y1, x2, y2)

        # ğŸ“¸ Ø¯Ú©Ù…Ù‡ Ø¹Ú©Ø³ (Ú¯ÙˆØ´Ù‡ Ø¨Ø§Ù„Ø§ Ø±Ø§Ø³Øª) - Ù„Ù…Ø³ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ØªØ§ÛŒÙ…Ø±
        photo_x1, photo_y1 = w - 140, 20
        photo_x2, photo_y2 = w - 20, 80
        photo_touching = self.is_finger_touching_button(hand_results, frame.shape, (photo_x1, photo_y1, photo_x2, photo_y2))
        
        photo_color = (0, 200, 0) if photo_touching else (200, 200, 200)
        cv2.rectangle(frame, (photo_x1, photo_y1), (photo_x2, photo_y2), photo_color, -1)
        cv2.rectangle(frame, (photo_x1, photo_y1), (photo_x2, photo_y2), (0, 0, 0), 2)
        
        frame = self.put_persian_text(frame, "Ø¹Ú©Ø³", (photo_x1 + 30, photo_y1 + 15), 1.0, (0, 0, 0))
        
        buttons["photo"] = (photo_x1, photo_y1, photo_x2, photo_y2)

        # ğŸ“¹ Ø¯Ú©Ù…Ù‡ Ø¶Ø¨Ø· ÙˆÛŒØ¯ÛŒÙˆ
        video_x1, video_y1 = w - 140, 100
        video_x2, video_y2 = w - 20, 160
        video_touching = self.is_finger_touching_button(hand_results, frame.shape, (video_x1, video_y1, video_x2, video_y2))
        
        # Ù…Ø¯ÛŒØ±ÛŒØª Ù„Ù…Ø³ Ø¶Ø¨Ø· ÙˆÛŒØ¯ÛŒÙˆ
        if video_touching and self.button_cooldown == 0:
            self.toggle_recording()
            self.button_cooldown = 30
        
        video_color = (0, 0, 200) if self.is_recording else (200, 200, 200) # Ù‚Ø±Ù…Ø² Ø¯Ø± Ø­Ø§Ù„ Ø¶Ø¨Ø·
        cv2.rectangle(frame, (video_x1, video_y1), (video_x2, video_y2), video_color, -1)
        cv2.rectangle(frame, (video_x1, video_y1), (video_x2, video_y2), (0, 0, 0), 2)
        
        text = "ØªÙˆÙ‚Ù" if self.is_recording else "Ø¶Ø¨Ø·"
        frame = self.put_persian_text(frame, text, (video_x1 + 30, video_y1 + 15), 1.0, (255, 255, 255))
        
        buttons["video"] = (video_x1, video_y1, video_x2, video_y2)

        # â° Ø¯Ú©Ù…Ù‡ ØªØ§ÛŒÙ…Ø±
        timer_x1, timer_y1 = w - 140, 180
        timer_x2, timer_y2 = w - 20, 240
        timer_touching = self.is_finger_touching_button(hand_results, frame.shape, (timer_x1, timer_y1, timer_x2, timer_y2))
        
        # Ù…Ø¯ÛŒØ±ÛŒØª Ù„Ù…Ø³ ØªØ§ÛŒÙ…Ø±
        if timer_touching and self.button_cooldown == 0:
            self.start_timer()
            self.button_cooldown = 30
        
        # Ø§ØµÙ„Ø§Ø­ Ø±Ù†Ú¯ ØªØ§ÛŒÙ…Ø± Ø¨Ù‡ Ø²Ø±Ø¯
        timer_color = (0, 200, 200) if self.timer_active else (200, 200, 200) # Ø²Ø±Ø¯ (B:0, G:200, R:200)
        cv2.rectangle(frame, (timer_x1, timer_y1), (timer_x2, timer_y2), timer_color, -1)
        cv2.rectangle(frame, (timer_x1, timer_y1), (timer_x2, timer_y2), (0, 0, 0), 2)
        
        frame = self.put_persian_text(frame, "ØªØ§ÛŒÙ…Ø±", (timer_x1 + 25, timer_y1 + 15), 1.0, (0, 0, 0))
        
        buttons["timer"] = (timer_x1, timer_y1, timer_x2, timer_y2)

        return frame, buttons

    def draw_landmarks(self, frame: np.ndarray, pose_results: Any, hand_results: Any) -> np.ndarray:
        """Ø±Ø³Ù… Ø§Ø³Ú©Ù„Øª Ø¨Ø¯Ù† Ùˆ Ø¯Ø³Øª"""
        # Ø±Ø³Ù… Ø§Ø³Ú©Ù„Øª Ø¨Ø¯Ù†
        if pose_results and pose_results.pose_landmarks:
            mp_drawing.draw_landmarks(
                frame,
                pose_results.pose_landmarks,
                mp_pose.POSE_CONNECTIONS,
                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),
                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)
            )
        
        # Ø±Ø³Ù… Ø¯Ø³Øªâ€ŒÙ‡Ø§
        if hand_results and hand_results.multi_hand_landmarks:
            for hand_landmarks in hand_results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(
                    frame,
                    hand_landmarks,
                    mp_hands.HAND_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=2, circle_radius=3),
                    mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2)
                )
        
        return frame

    def display_info(self, frame: np.ndarray, pose_results: Any, hand_results: Any, face_results: Any) -> np.ndarray:
        """Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ùˆ ÙˆØ¶Ø¹ÛŒØª (ØªÙ…Ø§Ù…Ø§Ù‹ ÙØ§Ø±Ø³ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡)"""
        h, w = frame.shape[:2]
        
        # ÙˆØ¶Ø¹ÛŒØª ØªØ´Ø®ÛŒØµ
        status = "ÙØ¹Ø§Ù„" if pose_results and pose_results.pose_landmarks else "ØºÛŒØ±ÙØ¹Ø§Ù„"
        status_color = (0, 100, 0) if pose_results and pose_results.pose_landmarks else (0, 0, 100)
        frame = self.put_persian_text(frame, f"ÙˆØ¶Ø¹ÛŒØª: {status}", (20, h - 100), 0.7, status_color)
        
        # ØªØ§ÛŒÙ…Ø±
        if self.timer_active:
            # Ø²Ù…Ø§Ù† Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡
            seconds = self.timer_countdown // 30 + 1 
            frame = self.put_persian_text(frame, f"ØªØ§ÛŒÙ…Ø±: {seconds} Ø«Ø§Ù†ÛŒÙ‡", (20, h - 70), 0.8, (0, 0, 200))
        
        # Ø¶Ø¨Ø·
        if self.is_recording:
            duration = int(time.time() - self.recording_start_time)
            frame = self.put_persian_text(frame, f"Ø¶Ø¨Ø·: {duration} Ø«Ø§Ù†ÛŒÙ‡", (20, h - 40), 0.7, (0, 0, 200))
        
        # Ú˜Ø³Øªâ€ŒÙ‡Ø§
        gesture = self.detect_gestures(hand_results)
        if gesture:
            gesture_text = {"peace": "âœŒï¸ ØµÙ„Ø­", "thumbs_up": "ğŸ‘ Ø¹Ø§Ù„ÛŒ"}.get(gesture, gesture)
            frame = self.put_persian_text(frame, f"Ú˜Ø³Øª: {gesture_text}", (w - 200, h - 40), 0.7, (200, 0, 200))
        
        # Ù„Ø¨Ø®Ù†Ø¯
        if self.detect_smile(face_results):
            frame = self.put_persian_text(frame, "ğŸ˜Š Ù„Ø¨Ø®Ù†Ø¯", (w - 200, h - 70), 0.7, (0, 200, 200))
        
        return frame

    # ------------------------------------------------------------------------------------------------------
    # ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ùˆ Ú©Ù…Ú©ÛŒ
    # ------------------------------------------------------------------------------------------------------
    
    def run(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡"""
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Ø¯ÙˆØ±Ø¨ÛŒÙ†")
            return
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø¨Ø¹Ø§Ø¯ Ø¯ÙˆØ±Ø¨ÛŒÙ†
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        print("ğŸš€ Ø³ÙˆÙ¾Ø± Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† ØªØ´Ø®ÛŒØµ Ù¾ÙˆØ² Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯!")
        print("ğŸ¯ Ø§Ù…Ú©Ø§Ù†Ø§Øª: Ø¹Ú©Ø³ØŒ ÙÛŒÙ„Ù…ØŒ ØªØ§ÛŒÙ…Ø±ØŒ ÙÛŒÙ„ØªØ±ØŒ ØªØ´Ø®ÛŒØµ Ú˜Ø³Øª Ùˆ Ù„Ø¨Ø®Ù†Ø¯!")
        
        try:
            while True:
                ret, frame = self.cap.read()
                if not ret:
                    break
                
                # Ø¢ÛŒÙ†Ù‡â€ŒØ§ÛŒ Ú©Ø±Ø¯Ù† ÙØ±ÛŒÙ…
                frame = cv2.flip(frame, 1)
                
                # ** Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ±ÛŒÙ… Ø¯Ø± Ø±Ø´ØªÙ‡ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ (Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ) **
                pose_results, hand_results, face_results = self.process_frame(frame)
                
                # Ø§Ø¹Ù…Ø§Ù„ ÙÛŒÙ„ØªØ±
                frame = self.apply_filter(frame, self.current_filter)
                
                # Ø±Ø³Ù… Ø§Ø³Ú©Ù„Øª
                frame = self.draw_landmarks(frame, pose_results, hand_results)
                
                # Ø±Ø³Ù… Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ù„Ù…Ø³
                frame, buttons = self.draw_virtual_buttons(frame, hand_results)
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ù„Ù…Ø³ Ø¯Ú©Ù…Ù‡ Ø¹Ú©Ø³ (Ø§Ú¯Ø± ØªØ§ÛŒÙ…Ø± ÙØ¹Ø§Ù„ Ù†ÛŒØ³Øª)
                if "photo" in buttons and self.button_cooldown == 0:
                    photo_touching = self.is_finger_touching_button(hand_results, frame.shape, buttons["photo"])
                    if photo_touching:
                         if not self.timer_active:
                            self.take_photo(frame)
                            self.button_cooldown = 30
                
                # Ù…Ø¯ÛŒØ±ÛŒØª ØªØ§ÛŒÙ…Ø±
                if self.timer_active:
                    self.timer_countdown -= 1
                    if self.timer_countdown <= 0:
                        self.timer_active = False
                        self.take_photo(frame)  # Ø¹Ú©Ø³ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø¹Ø¯ Ø§Ø² Ø§ØªÙ…Ø§Ù… ØªØ§ÛŒÙ…Ø±
                
                # Ø¶Ø¨Ø· ÙˆÛŒØ¯ÛŒÙˆ
                if self.is_recording and self.video_writer:
                    self.video_writer.write(frame)
                
                # Ú©Ø§Ù‡Ø´ Ú©ÙˆÙ„â€ŒØ¯Ø§ÙˆÙ†
                if self.button_cooldown > 0:
                    self.button_cooldown -= 1
                
                # Ø§ÙÚ©Øª ÙÙ„Ø´
                if self.flash_effect > 0:
                    flash_overlay = np.ones_like(frame) * 255
                    # ØªØ±Ú©ÛŒØ¨ ÙØ±ÛŒÙ… Ø¨Ø§ Ø±Ù†Ú¯ Ø³ÙÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ ÙÙ„Ø´
                    frame = cv2.addWeighted(frame, 0.7, flash_overlay, 0.3, 0)
                    self.flash_effect -= 1
                
                # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆØ¶Ø¹ÛŒØª
                frame = self.display_info(frame, pose_results, hand_results, face_results)
                
                # Ù†Ù…Ø§ÛŒØ´ ÙØ±ÛŒÙ…
                cv2.imshow('Super Pose Detection ğŸš€', frame)
                
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
                    
        except KeyboardInterrupt:
            print("\nâ¹ï¸ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
        finally:
            self.cleanup()

    def cleanup(self):
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹"""
        if self.is_recording and self.video_writer:
            self.video_writer.release()
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        print("âœ… Ù…Ù†Ø§Ø¨Ø¹ Ø¢Ø²Ø§Ø¯ Ø´Ø¯Ù†Ø¯")

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    print("ğŸ‰ Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÙˆÙ¾Ø± Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù†...")
    app = SuperPoseDetector()
    app.run()

if __name__ == "__main__":
    main()